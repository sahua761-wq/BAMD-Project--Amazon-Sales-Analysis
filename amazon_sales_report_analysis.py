# -*- coding: utf-8 -*-
"""Amazon_Sales_Report_Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bOsxqGcvgWgMZe0zkLqTVGOvg8U_x4km
"""

#Import our standard libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#Preprocessing
from sklearn import preprocessing
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split

#Splitting & Tuning
from sklearn.model_selection import cross_val_score, GridSearchCV

#models used
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree

#Evaluation
from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report
from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score

#suppress warnings
import warnings
warnings.filterwarnings('ignore')

#Load Clearned Dataset
fname = "Amazon_Sale_Report.csv"
df = pd.read_csv(fname, encoding='latin-1')

df.shape

df.isnull().sum()

df.head()

"""### Cleaning Data- Imputing values"""

df.info()

df["currency"].fillna("INR", inplace=True)
df["Amount"].fillna(0, inplace = True)
df["fulfilled-by"].fillna("Others", inplace = True)

df.info()

df.head()

#Cleaning the data
pd.DataFrame(df).isna().sum()

pd.DataFrame(df).nunique()

#dropping variables where most of the data is missing and date which is redundant
df = df.drop(columns = ['index','Order ID','ASIN','Courier Status','ship-postal-code','ship-country','ship-city','currency','Unnamed: 22'])

df.dropna(subset=['ship-state'], inplace=True)

df['promotion-ids'].fillna("None", inplace = True)

pd.DataFrame(df).isna().sum()

"""## Cleaning Data- Adressing errors in state names"""

df['ship-state'].value_counts()

# Visualising distribution of states
sns.catplot(x='ship-state', data = df, order = df['ship-state'].value_counts().index,kind = 'count', hue = 'ship-state',aspect = 3)
plt.xticks(rotation = 90)
plt.show()

#Addressing issue with state names
df['ship-state'] = df['ship-state'].str.upper()

df['ship-state'].unique()

df['ship-state']=df['ship-state'].replace(['NEW DELHI','DELHI'],'NEW DELHI')
df['ship-state']=df['ship-state'].replace(['ODISHA','ORISSA'],'ODISHA')
df['ship-state']=df['ship-state'].replace(['NL','NAGALAND'],'NAGALAND')
df['ship-state']=df['ship-state'].replace(['PUNJAB/MOHALI/ZIRAKPUR','PB'],'PUNJAB')
df['ship-state']=df['ship-state'].replace(['RJ','RAJSTHAN','RAJSHTHAN'],'RAJASTHAN')
df['ship-state']=df['ship-state'].replace(['PONDICHERRY','PUDUCHERRY'],'PUDUCHERRY')
df['ship-state']=df['ship-state'].replace(['AR'],'ARUNACHAL PRADESH')
df['ship-state']=df['ship-state'].replace(['APO'],'WEST BENGAL')

df['ship-state'].unique()

# Visualising distribution of states
sns.catplot(x='ship-state', data = df, order = df['ship-state'].value_counts().index,kind = 'count', hue = 'ship-state',aspect = 3)
plt.xticks(rotation = 90)
plt.show()

"""### Add Regions"""

# Mapping dictionary for Indian states & UTs to regions
region_dict = {
    'North': ['PUNJAB', 'HARYANA', 'HIMACHAL PRADESH', 'UTTARAKHAND', 'UTTAR PRADESH', 'JAMMU & KASHMIR', 'NEW DELHI', 'CHANDIGARH', 'LADAKH', 'MADHYA PRADESH'],
    'South': ['KARNATAKA', 'KERALA', 'TAMIL NADU', 'ANDHRA PRADESH', 'TELANGANA', 'PUDUCHERRY', 'LAKSHADWEEP', 'ANDAMAN & NICOBAR'],
    'East': ['BIHAR', 'ODISHA', 'WEST BENGAL', 'JHARKHAND', 'CHHATTISGARH', 'ASSAM', 'MEGHALAYA', 'MANIPUR', 'MIZORAM', 'NAGALAND', 'TRIPURA', 'ARUNACHAL PRADESH', 'SIKKIM'],
    'West': ['RAJASTHAN', 'GUJARAT', 'MAHARASHTRA', 'GOA', 'DADRA AND NAGAR'],
}
# Flatten mapping for .map()
flat_map = {state: region for region, states in region_dict.items() for state in states}
df['Region'] = df['ship-state'].map(flat_map)

df['Region'].value_counts()

df['ship-state'].value_counts()

df.info()

df['Region'].fillna('South', inplace = True)

"""### Add year & month columns"""

df['Date'] = pd.to_datetime(df['Date'])
df['Month'] = df['Date'].dt.month
df['Day_Name'] = df['Date'].dt.day_name()
df['Week'] = df['Date'].dt.isocalendar().week

df.head()

df['Month'].unique()

df['Week'].unique()

sns.catplot(x='Month', data = df, order = df['Month'].value_counts().index,kind = 'count', hue = 'Month',aspect = 3)
plt.show()

df.drop(columns = 'Date')

df.nunique()

df['promotion_flag'] = np.where(df['promotion-ids'] == 'None', 0, 1)

df.info()

print(df.columns.tolist())

region_dfs = {region: df[df['Region'] == region] for region in df['Region'].unique()}

"""## North"""

N_df = region_dfs['North'].groupby(
    ['Category', 'Size', 'B2B','promotion-ids', 'Fulfilment', 'Sales Channel ', 'fulfilled-by'],
    as_index=False
).agg({
    'Qty': 'sum',
    'Amount': 'sum'
})

N_df['Qty'].describe()

N_df['Volume_Class'] = pd.qcut(
    N_df['Qty'],
    q=2,
    labels=[0, 1],
    duplicates='drop')

sns.countplot(x='Volume_Class', data=N_df, order=[0, 1], palette='viridis')
plt.show()

N_df.info()

cat_cols = ['Category', 'Size', 'B2B','promotion-ids', 'Fulfilment', 'Sales Channel ', 'fulfilled-by']
N_df[cat_cols] = N_df[cat_cols].astype('category')

"""### One Hot Encoding"""

#Create Independent and Dependent Variables
X1 = N_df.drop(['Qty', 'Amount', 'Volume_Class'], axis = 1)
y1 = N_df['Volume_Class']

X1 = pd.get_dummies(X1)

# Split the data into training and testing set
X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=428)

print(X1_train.shape)
print(X1_test.shape)
print(y1_train.shape)
print(y1_test.shape)

"""### Logistic Regression"""

# Fit logistic regression
lr_model = LogisticRegression()
lr_model.fit(X1_train,y1_train)

# Predict for test data
predictions = lr_model.predict(X1_test)

"""### Logistic Regression Evaluation"""

# Check accuracy
print('training accuracy:', lr_model.score(X1_train,y1_train))
print('testing accuracy:', lr_model.score(X1_test,y1_test))

cm1 = confusion_matrix(y1_test,predictions)
print(cm1)

print("\n Logistic Regression Report:\n", classification_report(y1_test, predictions, target_names=['Low', 'High']))

# AUC and ROC
prediction_prob = lr_model.predict_proba(X1_test)[:,1]
false_positve_rate, true_positive_rate, thresholds = roc_curve(y1_test, prediction_prob)
roc_auc = auc(false_positve_rate, true_positive_rate)

print("AUC - ", format(roc_auc))
# Plot Precision Recall curve
plt.plot(false_positve_rate, true_positive_rate)
plt.xlabel("FPR")
plt.ylabel("TPR")
plt.title("ROC Curve")
plt.show()

"""### Logistic Regression for different thresholds"""

#Try different Threshold and check precision and recall
prediction_prob = lr_model.predict_proba(X1_test)[:,1]
type(prediction_prob)
#predictions_threshold =
prediction_prob[prediction_prob > 0.8] = 1
prediction_prob[prediction_prob <= 0.8] = 0

print("\n Logistic Regression with 0.8 Threshold Report:\n", classification_report(y1_test, prediction_prob, target_names=['Low', 'High']))

prediction_prob = lr_model.predict_proba(X1_test)[:,1]
type(prediction_prob)
#predictions_threshold =
prediction_prob[prediction_prob > 0.3] = 1
prediction_prob[prediction_prob <= 0.3] = 0
print("\n Logistic Regression 0.3 threshold Report:\n", classification_report(y1_test, prediction_prob, target_names=['Low', 'High']))

"""### Decision Trees"""

#Decision Trees
from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree

def print_results(results):
    print('BEST PARAMS: {}\n'.format(results.best_params_))

    means = results.cv_results_['mean_test_score']
    stds = results.cv_results_['std_test_score']
    for mean, std, params in zip(means, stds, results.cv_results_['params']):
        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))

#start with an initial guess for params
param_grid = {
    'max_depth': [10,20,30, 40],
    'min_samples_split': [20,40,60,80,100],
    'min_impurity_decrease': [0, 0.0005, 0.001, 0.005, 0.01],
    'criterion':['gini','entropy']
}

#Run Gridsearch
gridsearch = GridSearchCV(DecisionTreeClassifier(random_state = 1),
                         param_grid,
                         cv = 5,
                         n_jobs = -1)
gridsearch.fit(X1_train, y1_train)

print('Initial score:', gridsearch.best_score_)
print('Initial parameters:', gridsearch.best_params_)

#Take the best estimator
bestCtree = gridsearch.best_estimator_
predictions = bestCtree.predict(X1_test)
print(accuracy_score(y1_test, predictions))

print(classification_report(y1_test, predictions))

"""### Post-Pruning (CCP)"""

#try ccp
param_grid = {
    "ccp_alpha":[0.001, 0.005, 0.01, 0.05, 0.1]
}

gridsearch_cp = GridSearchCV(DecisionTreeClassifier(random_state = 1),
                         param_grid,
                         cv = 5,
                         n_jobs = -1)
gridsearch_cp.fit(X1_train, y1_train)

print('CCP Score:', gridsearch_cp.best_score_)
print('CCP Parameters:', gridsearch_cp.best_params_)
#Take the best estimator
bestCtree_cp = gridsearch_cp.best_estimator_
pred_cp = bestCtree_cp.predict(X1_test)
print(accuracy_score(y1_test, pred_cp))
print(classification_report(y1_test, pred_cp))

"""### Random Forest"""

from sklearn.ensemble import RandomForestClassifier #RandomForestClassifier

#Create an object for random forest classifier- assumes DecisionTree
rnd_clf = RandomForestClassifier(
    n_estimators = 500,
    max_depth = 10,
    n_jobs = -1,
    random_state = 0
)

#Fit the model
rnd_clf.fit(X1_train, y1_train)

#predict using the model
rf_pred = rnd_clf.predict(X1_test)

#Check the accuracy score
print(accuracy_score(y1_test, rf_pred))

#print feature importance
features = X1_test.columns
importances = rnd_clf.feature_importances_
indices = np.argsort(importances)[::-1][:10]

plt.title('Feature Importances')
plt.barh(range(len(indices)), importances[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.xlabel('Relative Importance')
plt.show()

print(classification_report(y1_test, rf_pred))

"""### Extra Trees"""

from sklearn.ensemble import ExtraTreesClassifier

#Create an object for extra tree
ext_clf = ExtraTreesClassifier(
    n_estimators = 500,
    max_depth = 10,
    n_jobs = -1,
    random_state = 0
)

ext_clf.fit(X1_train, y1_train)

ext_pred = ext_clf.predict(X1_test)

print(accuracy_score(y1_test, ext_pred))

"""## Boosting

### Adaboost
"""

from sklearn.ensemble import AdaBoostClassifier

#create an object
ada_clf = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth = 1),
    n_estimators = 200,
    learning_rate = 0.05,
    random_state = 0
)

ada_clf.fit(X1_train, y1_train)

ada_pred = ada_clf.predict(X1_test)
print(accuracy_score(y1_test, ada_pred))

print(classification_report(y1_test, ada_pred))

"""### XGBoost"""

from xgboost import XGBClassifier

#Create an object
xgb_clf = XGBClassifier(early_stopping_rounds = 2)

#Run the model
xgb_clf.fit(X1_train, y1_train,
            eval_set = [(X1_test, y1_test)])

#get the predictions
xgb_pred = xgb_clf.predict(X1_test)

#check for accuracy
print(accuracy_score(y1_test, xgb_pred))

print(classification_report(y1_test, xgb_pred))

"""### Choosing Best Model"""

# Accuracy Score
from sklearn.metrics import accuracy_score, precision_score, recall_score
for mdl in [lr_model, bestCtree, bestCtree_cp, rnd_clf, ext_clf, ada_clf, xgb_clf]:
    y1_pred = mdl.predict(X1_test)
    accuracy = round(accuracy_score(y1_test, y1_pred), 3)
    precision = round(precision_score(y1_test, y1_pred), 3)
    recall = round(recall_score(y1_test, y1_pred), 3)
    print('mdl: {} / # -- A: {} / P: {} / R: {}'.format(mdl.__class__.__name__,  accuracy,
                                                                         precision,
                                                                         recall))

"""### Hence Logistic Regression will be used for all other datasets"""

#Try different Threshold and check precision and recall
prediction_prob = lr_model.predict_proba(X1_test)[:,1]
type(prediction_prob)
#predictions_threshold =
for theta in np.arange(0.0, 1.05, 0.05):
    preds = (prediction_prob > theta).astype(int)  # convert to 0/1 labels
    precision = precision_score(y1_test, preds, average='binary')
    recall = recall_score(y1_test, preds, average='binary')
    print(f"Threshold: {theta:.2f} | Precision: {precision:.2f} | Recall: {recall:.2f}")

# Get the quantity column from the original dataset for the test set rows
qty_test = N_df.loc[X1_test.index, 'Qty']  # replace 'Qty' with actual column name
amount_test = N_df.loc[X1_test.index, 'Amount']

prediction_prob = lr_model.predict_proba(X1_test)[:, 1]

results = []

for theta in np.arange(0.0, 1.05, 0.05):
    y1_pred = (prediction_prob > theta).astype(int)

    precision = precision_score(y1_test, y1_pred, pos_label=1)
    recall = recall_score(y1_test, y1_pred, pos_label=1)

    # Masks
    tp_mask = (y1_test == 1) & (y1_pred == 1)
    fp_mask = (y1_test != 1) & (y1_pred == 1)

    qty_tp = qty_test[tp_mask].sum()
    qty_fp = qty_test[fp_mask].sum()
    rev_tp = amount_test[tp_mask].sum()
    rev_fp = amount_test[fp_mask].sum()

    avg_usp_tp = (amount_test[tp_mask] / qty_test[tp_mask]).mean()
    avg_usp_fp = (amount_test[fp_mask] / qty_test[fp_mask]).mean()

    results.append({
        'Threshold': round(theta, 2),
        'Precision': round(precision, 2),
        'Recall': round(recall, 2),
        'Qty_TP': int(qty_tp),
        'Qty_FP': int(qty_fp),
        'Revenue_TP': round(rev_tp, 2),
        'Revenue_FP': round(rev_fp, 2),
        'Avg_USP_TP': round(avg_usp_tp, 2),
        'Avg_USP_FP': round(avg_usp_fp, 2)
    })

results_df = pd.DataFrame(results)
print(results_df)

"""### Threshold ≈ 0.35–0.40 seems optimal — high enough precision to avoid too many wrong positives, recall still solid, and revenue from true positives remains high while revenue from false positives is lower.

### Hence we will be going ahead with threshold of 0.4 for other regions as well

## South
"""

S_df = region_dfs['South'].groupby(
    ['Category','Size', 'B2B','promotion-ids', 'Fulfilment', 'Sales Channel ', 'fulfilled-by'],
    as_index=False
).agg({
    'Qty': 'sum',
    'Amount': 'sum'
})

S_df['Volume_Class'] = pd.qcut(
    S_df['Qty'],
    q=2,
    labels=[0, 1],
    duplicates='drop')

sns.countplot(x='Volume_Class', data=S_df, order=[0, 1], palette='viridis')
plt.show()

cat_cols = ['Category', 'Size', 'B2B','promotion-ids', 'Fulfilment', 'Sales Channel ', 'fulfilled-by']
S_df[cat_cols] = S_df[cat_cols].astype('category')

#Create Independent and Dependent Variables
X2 = S_df.drop(['Qty', 'Amount', 'Volume_Class'], axis = 1)
y2 = S_df['Volume_Class']

X2 = pd.get_dummies(X2)

# Split the data into training and testing set
X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=428)

print(X2_train.shape)
print(X2_test.shape)
print(y2_train.shape)
print(y2_test.shape)

# Fit logistic regression
lr_model2 = LogisticRegression()
lr_model2.fit(X2_train,y2_train)

prediction_probS = lr_model2.predict_proba(X2_test)[:,1]
type(prediction_probS)
#predictions_threshold =
prediction_probS[prediction_probS > 0.4] = 1
prediction_probS[prediction_probS <= 0.4] = 0

print("\n Logistic Regression 0.4 threshold Report:\n", classification_report(y2_test, prediction_probS, target_names=['Low', 'High']))

"""## West"""

W_df = region_dfs['West'].groupby(
    ['Category', 'Size', 'B2B','promotion-ids', 'Fulfilment', 'Sales Channel ', 'fulfilled-by'],
    as_index=False
).agg({
    'Qty': 'sum',
    'Amount': 'sum'
})

W_df['Volume_Class'] = pd.qcut(
    W_df['Qty'],
    q=2,
    labels=[0, 1],
    duplicates='drop')

sns.countplot(x='Volume_Class', data=W_df, order=[0, 1], palette='viridis')
plt.show()

W_df[cat_cols] = W_df[cat_cols].astype('category')

#Create Independent and Dependent Variables
X3 = W_df.drop(['Qty', 'Amount', 'Volume_Class', ], axis = 1)
y3 = W_df['Volume_Class']

X3 = pd.get_dummies(X3)

# Split the data into training and testing set
X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=428)

print(X3_train.shape)
print(X3_test.shape)
print(y3_train.shape)
print(y3_test.shape)

# Fit logistic regression
lr_model3 = LogisticRegression()
lr_model3.fit(X3_train,y3_train)

prediction_probW = lr_model3.predict_proba(X3_test)[:,1]
type(prediction_probW)
#predictions_threshold =
prediction_probW[prediction_probW > 0.4] = 1
prediction_probW[prediction_probW <= 0.4] = 0

print("\n Logistic Regression 0.4 threshold Report:\n", classification_report(y3_test, prediction_probW, target_names=['Low', 'High']))

"""## East"""

E_df = region_dfs['East'].groupby(
    ['Category', 'Size', 'B2B','promotion-ids', 'Fulfilment', 'Sales Channel ', 'fulfilled-by'],
    as_index=False
).agg({
    'Qty': 'sum',
    'Amount': 'sum'
})

E_df['Volume_Class'] = pd.qcut(
    E_df['Qty'],
    q=2,
    labels=[0, 1],
    duplicates='drop')

sns.countplot(x='Volume_Class', data=E_df, order=[0, 1], palette='viridis')
plt.show()

E_df[cat_cols] = E_df[cat_cols].astype('category')

#Create Independent and Dependent Variables
X4 = E_df.drop(['Qty', 'Amount', 'Volume_Class'], axis = 1)
y4 = E_df['Volume_Class']

X4 = pd.get_dummies(X4)

# Split the data into training and testing set
X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.2, random_state=428)

print(X4_train.shape)
print(X4_test.shape)
print(y4_train.shape)
print(y4_test.shape)

# Fit logistic regression
lr_model4 = LogisticRegression()
lr_model4.fit(X4_train,y4_train)

prediction_probE = lr_model4.predict_proba(X4_test)[:,1]
type(prediction_probE)
#predictions_threshold =
prediction_probE[prediction_probE > 0.4] = 1
prediction_probE[prediction_probE <= 0.4] = 0

print("\n Logistic Regression 0.4 threshold Report:\n", classification_report(y4_test, prediction_probE, target_names=['Low', 'High']))

# Amazon Sales SKU Classification Streamlit App
import streamlit as st
from sklearn.preprocessing import LabelEncoder
import plotly.express as px
import plotly.graph_objects as go

# Page configuration
st.set_page_config(page_title="Amazon SKU Classifier", page_icon="📦", layout="wide")

all_regional_data = pd.concat([
    N_df.assign(Region='North'),
    S_df.assign(Region='South'),
    E_df.assign(Region='East'),
    W_df.assign(Region='West')
], ignore_index=True)


# Title and description
st.title("📦 Amazon Sales SKU Classifier")
st.subheader("Predicting SKU Performance in Indian Regions")

# Add description
st.markdown("""
This application classifies SKUs based on whether they will sell more than 2 quantities in a specific region.
- **Class 0**: SKU will sell 2 or fewer quantities
- **Class 1**: SKU will sell more than 2 quantities
""")

# Sidebar for navigation
st.sidebar.title("Navigation")
nav = st.sidebar.radio("Choose Section", ["Home", "SKU Classification", "Data Analysis"])

# Home Section
if nav == 'Home':
    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("""
        ## About This Application

        This application helps predict SKU performance in different regions of India based on various product characteristics.

        **Features:**
        - Region-specific predictions for North, South, East, and West India
        - Classification based on multiple product attributes
        - Interactive prediction interface
        - Data visualization capabilities

        **How to Use:**
        1. Navigate to the "SKU Classification" section
        2. Select your target region
        3. Input product characteristics
        4. Get prediction results instantly
        """)

    with col2:
        # Display some statistics
        st.markdown("### Quick Stats")
        st.metric("Total Regions", "4")
        st.metric("Product Categories", "9")
        st.metric("Classification Classes", "2")

        # Calculate percentages by region
        region_stats = all_regional_data.groupby(['Region', 'Volume_Class']).size().unstack(fill_value=0)
        region_percentages = region_stats.div(region_stats.sum(axis=1), axis=0) * 100

        fig = go.Figure(data=[
            go.Bar(name='Class 0 (≤2 quantities)',
                  x=region_percentages.index,
                  y=region_percentages[0] if 0 in region_percentages.columns else [0]*len(region_percentages)),
            go.Bar(name='Class 1 (>2 quantities)',
                  x=region_percentages.index,
                  y=region_percentages[1] if 1 in region_percentages.columns else [0]*len(region_percentages))
        ])
        fig.update_layout(
            title="Actual Volume Class Distribution by Region (%)",
            barmode='stack',
            height=400,
            yaxis_title="Percentage (%)"
        )
        st.plotly_chart(fig, use_container_width=True)

# SKU Classification Section
elif nav == 'SKU Classification':
    st.header("🎯 SKU Performance Prediction")

    # Region selection
    st.markdown("### Step 1: Select Target Region")
    selected_region = st.selectbox("Choose the region for prediction:", REGIONS, index=0)

    st.markdown(f"**Selected Region:** {selected_region}")
    st.divider()
    if selected_region == 'North':
        model = lr_model
    elif selected_region == 'South':
        model = lr_model2
    elif selected_region == 'West':
        model = lr_model3
    elif selected_region == 'East':
        model = lr_model4

    # Input form
    st.markdown("### Step 2: Enter Product Details")

    col1, col2 = st.columns(2)

    with col1:
        category = st.selectbox("Product Category:", CATEGORIES, index=0)
        size = st.selectbox("Size:", SIZES, index=6)  # Default to 'L'
        b2b = st.selectbox("B2B:", B2B_OPTIONS, index=1)  # Default to 'FALSE'

    with col2:
        promotion_ids = st.selectbox("Promotion IDs:", PROMOTION_IDS, index=0)
        fulfillment = st.selectbox("Fulfillment:", FULFILLMENT, index=0)  # Default to 'Amazon'
        sales_channel = st.selectbox("Sales Channel:", SALES_CHANNEL, index=0)  # Default to 'Amazon.in'

    st.divider()

    # Prediction section
    st.markdown("### Step 3: Get Prediction")

    col1, col2, col3 = st.columns([1, 2, 1])

    with col2:
        if st.button("🚀 Predict SKU Performance", type="primary", use_container_width=True):
            # Encode features
            encoded_features = encode_features(category, size, b2b, promotion_ids, fulfillment, sales_channel)

            # Make prediction (replace with your actual prediction logic)
            prediction = model.predict([encoded_features])[0]
            prediction_proba = model.predict_proba([encoded_features])[0]

            st.success("Prediction Complete!")

            # Display results
            col_result1, col_result2 = st.columns(2)

            with col_result1:
                if prediction == 1:
                    st.success(f"**Prediction: Class {prediction}**")
                    st.write("✅ This SKU is predicted to sell **MORE than 2 quantities** in the selected region.")
                else:
                    st.warning(f"**Prediction: Class {prediction}**")
                    st.write("⚠️ This SKU is predicted to sell **2 or FEWER quantities** in the selected region.")

            with col_result2:
                st.markdown("**Prediction Confidence:**")
                st.write(f"Class 0 probability: {prediction_proba[0]:.2%}")
                st.write(f"Class 1 probability: {prediction_proba[1]:.2%}")

                # Confidence bar
                confidence = max(prediction_proba)
                st.progress(confidence)
                st.write(f"Confidence Level: {confidence:.2%}")

    # Display input summary
    with st.expander("📋 Input Summary"):
        input_data = {
            "Parameter": ["Region", "Category", "Size", "B2B", "Promotion IDs", "Fulfillment", "Sales Channel"],
            "Value": [selected_region, category, size, b2b, promotion_ids, fulfillment, sales_channel]
        }
        input_df = pd.DataFrame(input_data)
        st.table(input_df)

# Data Analysis Section
elif nav == 'Data Analysis':
    st.header("📊 Data Analysis & Insights")

    # Sample visualizations (replace with actual data analysis)
    col1, col2 = st.columns(2)

    with col1:
        # Category distribution
        category_counts = pd.DataFrame({
            'Category': df['Category'],
            'Count': df['Category'].value_counts()
        })

        fig1 = px.bar(category_counts, x='Category', y='Count',
                     title='SKU Distribution by Category',
                     color='Count', color_continuous_scale='viridis')
        fig1.update_xaxis(tickangle=45)
        st.plotly_chart(fig1, use_container_width=True)

    with col2:
        # Regional performance
        # Count Volume class = 1 from each regional dataframe
        regional_performance = pd.DataFrame({
            'Region': ['North', 'South', 'East', 'West'],
            'High_Performance_SKUs': [
                (N_df['Volume_Class'] == 1).sum(),
                (S_df['Volume_Class'] == 1).sum(),  # Note: S_df not S-df
                (E_df['Volume_Class'] == 1).sum(),
                (W_df['Volume_Class'] == 1).sum()
            ]
        })

        fig2 = px.pie(regional_performance, values='High_Performance_SKUs', names='Region',
                     title='High Performance SKUs by Region (Volume Class = 1)')
        st.plotly_chart(fig2, use_container_width=True)

    # Size distribution
    size_performance = all_regional_data[all_regional_data['Volume_Class'] == 1]['Size'].value_counts().reset_index()
    size_performance.columns = ['Size', 'Class_1_Count']

    fig3 = px.bar(size_performance, x='Size', y='Class_1_Count',
                 title='Class 1 Count by Size',
                 labels={'Class_1_Count': 'Number of Class 1 SKUs'})
    st.plotly_chart(fig3, use_container_width=True)

    # Feature importance
    st.markdown("### Feature Importance")
    def get_feature_importance_from_models(models, feature_names):
        """Extract feature importance from logistic regression models"""

        # Combine coefficients from all regional models
        all_coefficients = []

        for region, model in models.items():
            # Get absolute values of coefficients
            coeffs = np.abs(model.coef_[0])  # model.coef_[0] for binary classification
            all_coefficients.append(coeffs)

        # Average coefficients across all regions
        avg_coefficients = np.mean(all_coefficients, axis=0)

        # Normalize to get relative importance (optional)
        normalized_importance = avg_coefficients / np.sum(avg_coefficients)

        return normalized_importance

    # Use it in your code
    feature_names = ['Category', 'Size', 'B2B', 'Promotion IDs', 'Fulfillment', 'Sales Channel']

    actual_models = {
        'North': lr_model,     # Your North region model
        'South': lr_model2,    # Your South region model
        'East': lr_model4,     # Your East region model
        'West': lr_model3      # Your West region model
    }
    # Get actual importance from your models
    importance_scores = get_feature_importance_from_models(actual_models, feature_names)

    feature_importance = pd.DataFrame({
        'Feature': feature_names,
        'Importance': importance_scores
    })

    fig4 = px.bar(feature_importance, x='Importance', y='Feature', orientation='h',
                 title='Feature Importance for SKU Classification (Based on Coefficient Magnitudes)')
    st.plotly_chart(fig4, use_container_width=True)


# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>Amazon Sales SKU Classifier | Built with Streamlit</p>
    <p>For questions or support, contact your data science team</p>
</div>
""", unsafe_allow_html=True)

