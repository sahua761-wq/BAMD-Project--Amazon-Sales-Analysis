# -*- coding: utf-8 -*-
"""Amazon_Sales_Report_Analysis

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bOsxqGcvgWgMZe0zkLqTVGOvg8U_x4km
"""

#Import our standard libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#Preprocessing
from sklearn import preprocessing
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split

#Splitting & Tuning
from sklearn.model_selection import cross_val_score, GridSearchCV

#models used
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree

#Evaluation
from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report
from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score

#suppress warnings
import warnings
warnings.filterwarnings('ignore')

#Load Clearned Dataset
fname = "Amazon_Sale_Report.csv"
df = pd.read_csv(fname, encoding='latin-1')

df.shape

df.isnull().sum()

df.head()

"""### Cleaning Data- Imputing values"""

df.info()

df["currency"].fillna("INR", inplace=True)
df["Amount"].fillna(0, inplace = True)
df["fulfilled-by"].fillna("Others", inplace = True)

df.info()

df.head()

#Cleaning the data
pd.DataFrame(df).isna().sum()

pd.DataFrame(df).nunique()

#dropping variables where most of the data is missing and date which is redundant
df = df.drop(columns = ['index','Order ID','ASIN','Courier Status','ship-postal-code','ship-country','ship-city','currency','Unnamed: 22'])

df.dropna(subset=['ship-state'], inplace=True)

df['promotion-ids'].fillna("None", inplace = True)

pd.DataFrame(df).isna().sum()

"""## Cleaning Data- Adressing errors in state names"""

df['ship-state'].value_counts()

# Visualising distribution of states
sns.catplot(x='ship-state', data = df, order = df['ship-state'].value_counts().index,kind = 'count', hue = 'ship-state',aspect = 3)
plt.xticks(rotation = 90)
plt.show()

#Addressing issue with state names
df['ship-state'] = df['ship-state'].str.upper()

df['ship-state'].unique()

df['ship-state']=df['ship-state'].replace(['NEW DELHI','DELHI'],'NEW DELHI')
df['ship-state']=df['ship-state'].replace(['ODISHA','ORISSA'],'ODISHA')
df['ship-state']=df['ship-state'].replace(['NL','NAGALAND'],'NAGALAND')
df['ship-state']=df['ship-state'].replace(['PUNJAB/MOHALI/ZIRAKPUR','PB'],'PUNJAB')
df['ship-state']=df['ship-state'].replace(['RJ','RAJSTHAN','RAJSHTHAN'],'RAJASTHAN')
df['ship-state']=df['ship-state'].replace(['PONDICHERRY','PUDUCHERRY'],'PUDUCHERRY')
df['ship-state']=df['ship-state'].replace(['AR'],'ARUNACHAL PRADESH')
df['ship-state']=df['ship-state'].replace(['APO'],'WEST BENGAL')

df['ship-state'].unique()

# Visualising distribution of states
sns.catplot(x='ship-state', data = df, order = df['ship-state'].value_counts().index,kind = 'count', hue = 'ship-state',aspect = 3)
plt.xticks(rotation = 90)
plt.show()

"""### Add Regions"""

# Mapping dictionary for Indian states & UTs to regions
region_dict = {
    'North': ['PUNJAB', 'HARYANA', 'HIMACHAL PRADESH', 'UTTARAKHAND', 'UTTAR PRADESH', 'JAMMU & KASHMIR', 'NEW DELHI', 'CHANDIGARH', 'LADAKH', 'MADHYA PRADESH'],
    'South': ['KARNATAKA', 'KERALA', 'TAMIL NADU', 'ANDHRA PRADESH', 'TELANGANA', 'PUDUCHERRY', 'LAKSHADWEEP', 'ANDAMAN & NICOBAR'],
    'East': ['BIHAR', 'ODISHA', 'WEST BENGAL', 'JHARKHAND', 'CHHATTISGARH', 'ASSAM', 'MEGHALAYA', 'MANIPUR', 'MIZORAM', 'NAGALAND', 'TRIPURA', 'ARUNACHAL PRADESH', 'SIKKIM'],
    'West': ['RAJASTHAN', 'GUJARAT', 'MAHARASHTRA', 'GOA', 'DADRA AND NAGAR'],
}
# Flatten mapping for .map()
flat_map = {state: region for region, states in region_dict.items() for state in states}
df['Region'] = df['ship-state'].map(flat_map)

df['Region'].value_counts()

df['ship-state'].value_counts()

df.info()

df['Region'].fillna('South', inplace = True)

"""### Add year & month columns"""

df['Date'] = pd.to_datetime(df['Date'])
df['Month'] = df['Date'].dt.month
df['Day_Name'] = df['Date'].dt.day_name()
df['Week'] = df['Date'].dt.isocalendar().week

df.head()

df['Month'].unique()

df['Week'].unique()

sns.catplot(x='Month', data = df, order = df['Month'].value_counts().index,kind = 'count', hue = 'Month',aspect = 3)
plt.show()

df.drop(columns = 'Date')

df.nunique()

df['promotion_flag'] = np.where(df['promotion-ids'] == 'None', 0, 1)

df.info()

print(df.columns.tolist())

region_dfs = {region: df[df['Region'] == region] for region in df['Region'].unique()}

"""## North"""

N_df = region_dfs['North'].groupby(
    ['Category', 'Size', 'B2B','promotion-ids', 'Fulfilment', 'Sales Channel ', 'fulfilled-by'],
    as_index=False
).agg({
    'Qty': 'sum',
    'Amount': 'sum'
})

N_df['Qty'].describe()

N_df['Volume_Class'] = pd.qcut(
    N_df['Qty'],
    q=2,
    labels=[0, 1],
    duplicates='drop')

sns.countplot(x='Volume_Class', data=N_df, order=[0, 1], palette='viridis')
plt.show()

N_df.info()

cat_cols = ['Category', 'Size', 'B2B','promotion-ids', 'Fulfilment', 'Sales Channel ', 'fulfilled-by']
N_df[cat_cols] = N_df[cat_cols].astype('category')

"""### One Hot Encoding"""

#Create Independent and Dependent Variables
X1 = N_df.drop(['Qty', 'Amount', 'Volume_Class'], axis = 1)
y1 = N_df['Volume_Class']

X1 = pd.get_dummies(X1)

# Split the data into training and testing set
X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=428)

print(X1_train.shape)
print(X1_test.shape)
print(y1_train.shape)
print(y1_test.shape)

"""### Logistic Regression"""

# Fit logistic regression
lr_model = LogisticRegression()
lr_model.fit(X1_train,y1_train)

# Predict for test data
predictions = lr_model.predict(X1_test)

"""### Logistic Regression Evaluation"""

# Check accuracy
print('training accuracy:', lr_model.score(X1_train,y1_train))
print('testing accuracy:', lr_model.score(X1_test,y1_test))

cm1 = confusion_matrix(y1_test,predictions)
print(cm1)

print("\n Logistic Regression Report:\n", classification_report(y1_test, predictions, target_names=['Low', 'High']))

# AUC and ROC
prediction_prob = lr_model.predict_proba(X1_test)[:,1]
false_positve_rate, true_positive_rate, thresholds = roc_curve(y1_test, prediction_prob)
roc_auc = auc(false_positve_rate, true_positive_rate)

print("AUC - ", format(roc_auc))
# Plot Precision Recall curve
plt.plot(false_positve_rate, true_positive_rate)
plt.xlabel("FPR")
plt.ylabel("TPR")
plt.title("ROC Curve")
plt.show()

"""### Logistic Regression for different thresholds"""

#Try different Threshold and check precision and recall
prediction_prob = lr_model.predict_proba(X1_test)[:,1]
type(prediction_prob)
#predictions_threshold =
prediction_prob[prediction_prob > 0.8] = 1
prediction_prob[prediction_prob <= 0.8] = 0

print("\n Logistic Regression with 0.8 Threshold Report:\n", classification_report(y1_test, prediction_prob, target_names=['Low', 'High']))

prediction_prob = lr_model.predict_proba(X1_test)[:,1]
type(prediction_prob)
#predictions_threshold =
prediction_prob[prediction_prob > 0.3] = 1
prediction_prob[prediction_prob <= 0.3] = 0
print("\n Logistic Regression 0.3 threshold Report:\n", classification_report(y1_test, prediction_prob, target_names=['Low', 'High']))

"""### Decision Trees"""

#Decision Trees
from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree

def print_results(results):
    print('BEST PARAMS: {}\n'.format(results.best_params_))

    means = results.cv_results_['mean_test_score']
    stds = results.cv_results_['std_test_score']
    for mean, std, params in zip(means, stds, results.cv_results_['params']):
        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))

#start with an initial guess for params
param_grid = {
    'max_depth': [10,20,30, 40],
    'min_samples_split': [20,40,60,80,100],
    'min_impurity_decrease': [0, 0.0005, 0.001, 0.005, 0.01],
    'criterion':['gini','entropy']
}

#Run Gridsearch
gridsearch = GridSearchCV(DecisionTreeClassifier(random_state = 1),
                         param_grid,
                         cv = 5,
                         n_jobs = -1)
gridsearch.fit(X1_train, y1_train)

print('Initial score:', gridsearch.best_score_)
print('Initial parameters:', gridsearch.best_params_)

#Take the best estimator
bestCtree = gridsearch.best_estimator_
predictions = bestCtree.predict(X1_test)
print(accuracy_score(y1_test, predictions))

print(classification_report(y1_test, predictions))

"""### Post-Pruning (CCP)"""

#try ccp
param_grid = {
    "ccp_alpha":[0.001, 0.005, 0.01, 0.05, 0.1]
}

gridsearch_cp = GridSearchCV(DecisionTreeClassifier(random_state = 1),
                         param_grid,
                         cv = 5,
                         n_jobs = -1)
gridsearch_cp.fit(X1_train, y1_train)

print('CCP Score:', gridsearch_cp.best_score_)
print('CCP Parameters:', gridsearch_cp.best_params_)
#Take the best estimator
bestCtree_cp = gridsearch_cp.best_estimator_
pred_cp = bestCtree_cp.predict(X1_test)
print(accuracy_score(y1_test, pred_cp))
print(classification_report(y1_test, pred_cp))

"""### Random Forest"""

from sklearn.ensemble import RandomForestClassifier #RandomForestClassifier

#Create an object for random forest classifier- assumes DecisionTree
rnd_clf = RandomForestClassifier(
    n_estimators = 500,
    max_depth = 10,
    n_jobs = -1,
    random_state = 0
)

#Fit the model
rnd_clf.fit(X1_train, y1_train)

#predict using the model
rf_pred = rnd_clf.predict(X1_test)

#Check the accuracy score
print(accuracy_score(y1_test, rf_pred))

#print feature importance
features = X1_test.columns
importances = rnd_clf.feature_importances_
indices = np.argsort(importances)[::-1][:10]

plt.title('Feature Importances')
plt.barh(range(len(indices)), importances[indices], color='b', align='center')
plt.yticks(range(len(indices)), [features[i] for i in indices])
plt.xlabel('Relative Importance')
plt.show()

print(classification_report(y1_test, rf_pred))

"""### Extra Trees"""

from sklearn.ensemble import ExtraTreesClassifier

#Create an object for extra tree
ext_clf = ExtraTreesClassifier(
    n_estimators = 500,
    max_depth = 10,
    n_jobs = -1,
    random_state = 0
)

ext_clf.fit(X1_train, y1_train)

ext_pred = ext_clf.predict(X1_test)

print(accuracy_score(y1_test, ext_pred))

"""## Boosting

### Adaboost
"""

from sklearn.ensemble import AdaBoostClassifier

#create an object
ada_clf = AdaBoostClassifier(
    DecisionTreeClassifier(max_depth = 1),
    n_estimators = 200,
    learning_rate = 0.05,
    random_state = 0
)

ada_clf.fit(X1_train, y1_train)

ada_pred = ada_clf.predict(X1_test)
print(accuracy_score(y1_test, ada_pred))

print(classification_report(y1_test, ada_pred))

"""### XGBoost"""

from xgboost import XGBClassifier

#Create an object
xgb_clf = XGBClassifier(early_stopping_rounds = 2)

#Run the model
xgb_clf.fit(X1_train, y1_train,
            eval_set = [(X1_test, y1_test)])

#get the predictions
xgb_pred = xgb_clf.predict(X1_test)

#check for accuracy
print(accuracy_score(y1_test, xgb_pred))

print(classification_report(y1_test, xgb_pred))

"""### Choosing Best Model"""

# Accuracy Score
from sklearn.metrics import accuracy_score, precision_score, recall_score
for mdl in [lr_model, bestCtree, bestCtree_cp, rnd_clf, ext_clf, ada_clf, xgb_clf]:
    y1_pred = mdl.predict(X1_test)
    accuracy = round(accuracy_score(y1_test, y1_pred), 3)
    precision = round(precision_score(y1_test, y1_pred), 3)
    recall = round(recall_score(y1_test, y1_pred), 3)
    print('mdl: {} / # -- A: {} / P: {} / R: {}'.format(mdl.__class__.__name__,  accuracy,
                                                                         precision,
                                                                         recall))

"""### Hence Logistic Regression will be used for all other datasets"""

#Try different Threshold and check precision and recall
prediction_prob = lr_model.predict_proba(X1_test)[:,1]
type(prediction_prob)
#predictions_threshold =
for theta in np.arange(0.0, 1.05, 0.05):
    preds = (prediction_prob > theta).astype(int)  # convert to 0/1 labels
    precision = precision_score(y1_test, preds, average='binary')
    recall = recall_score(y1_test, preds, average='binary')
    print(f"Threshold: {theta:.2f} | Precision: {precision:.2f} | Recall: {recall:.2f}")

# Get the quantity column from the original dataset for the test set rows
qty_test = N_df.loc[X1_test.index, 'Qty']  # replace 'Qty' with actual column name
amount_test = N_df.loc[X1_test.index, 'Amount']

prediction_prob = lr_model.predict_proba(X1_test)[:, 1]

results = []

for theta in np.arange(0.0, 1.05, 0.05):
    y1_pred = (prediction_prob > theta).astype(int)

    precision = precision_score(y1_test, y1_pred, pos_label=1)
    recall = recall_score(y1_test, y1_pred, pos_label=1)

    # Masks
    tp_mask = (y1_test == 1) & (y1_pred == 1)
    fp_mask = (y1_test != 1) & (y1_pred == 1)

    qty_tp = qty_test[tp_mask].sum()
    qty_fp = qty_test[fp_mask].sum()
    rev_tp = amount_test[tp_mask].sum()
    rev_fp = amount_test[fp_mask].sum()

    avg_usp_tp = (amount_test[tp_mask] / qty_test[tp_mask]).mean()
    avg_usp_fp = (amount_test[fp_mask] / qty_test[fp_mask]).mean()

    results.append({
        'Threshold': round(theta, 2),
        'Precision': round(precision, 2),
        'Recall': round(recall, 2),
        'Qty_TP': int(qty_tp),
        'Qty_FP': int(qty_fp),
        'Revenue_TP': round(rev_tp, 2),
        'Revenue_FP': round(rev_fp, 2),
        'Avg_USP_TP': round(avg_usp_tp, 2),
        'Avg_USP_FP': round(avg_usp_fp, 2)
    })

results_df = pd.DataFrame(results)
print(results_df)

"""### Threshold ‚âà 0.35‚Äì0.40 seems optimal ‚Äî high enough precision to avoid too many wrong positives, recall still solid, and revenue from true positives remains high while revenue from false positives is lower.

### Hence we will be going ahead with threshold of 0.4 for other regions as well

## South
"""

S_df = region_dfs['South'].groupby(
    ['Category','Size', 'B2B','promotion-ids', 'Fulfilment', 'Sales Channel ', 'fulfilled-by'],
    as_index=False
).agg({
    'Qty': 'sum',
    'Amount': 'sum'
})

S_df['Volume_Class'] = pd.qcut(
    S_df['Qty'],
    q=2,
    labels=[0, 1],
    duplicates='drop')

sns.countplot(x='Volume_Class', data=S_df, order=[0, 1], palette='viridis')
plt.show()

cat_cols = ['Category', 'Size', 'B2B','promotion-ids', 'Fulfilment', 'Sales Channel ', 'fulfilled-by']
S_df[cat_cols] = S_df[cat_cols].astype('category')

#Create Independent and Dependent Variables
X2 = S_df.drop(['Qty', 'Amount', 'Volume_Class'], axis = 1)
y2 = S_df['Volume_Class']

X2 = pd.get_dummies(X2)

# Split the data into training and testing set
X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=428)

print(X2_train.shape)
print(X2_test.shape)
print(y2_train.shape)
print(y2_test.shape)

# Fit logistic regression
lr_model2 = LogisticRegression()
lr_model2.fit(X2_train,y2_train)

prediction_probS = lr_model2.predict_proba(X2_test)[:,1]
type(prediction_probS)
#predictions_threshold =
prediction_probS[prediction_probS > 0.4] = 1
prediction_probS[prediction_probS <= 0.4] = 0

print("\n Logistic Regression 0.4 threshold Report:\n", classification_report(y2_test, prediction_probS, target_names=['Low', 'High']))

"""## West"""

W_df = region_dfs['West'].groupby(
    ['Category', 'Size', 'B2B','promotion-ids', 'Fulfilment', 'Sales Channel ', 'fulfilled-by'],
    as_index=False
).agg({
    'Qty': 'sum',
    'Amount': 'sum'
})

W_df['Volume_Class'] = pd.qcut(
    W_df['Qty'],
    q=2,
    labels=[0, 1],
    duplicates='drop')

sns.countplot(x='Volume_Class', data=W_df, order=[0, 1], palette='viridis')
plt.show()

W_df[cat_cols] = W_df[cat_cols].astype('category')

#Create Independent and Dependent Variables
X3 = W_df.drop(['Qty', 'Amount', 'Volume_Class', ], axis = 1)
y3 = W_df['Volume_Class']

X3 = pd.get_dummies(X3)

# Split the data into training and testing set
X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=428)

print(X3_train.shape)
print(X3_test.shape)
print(y3_train.shape)
print(y3_test.shape)

# Fit logistic regression
lr_model3 = LogisticRegression()
lr_model3.fit(X3_train,y3_train)

prediction_probW = lr_model3.predict_proba(X3_test)[:,1]
type(prediction_probW)
#predictions_threshold =
prediction_probW[prediction_probW > 0.4] = 1
prediction_probW[prediction_probW <= 0.4] = 0

print("\n Logistic Regression 0.4 threshold Report:\n", classification_report(y3_test, prediction_probW, target_names=['Low', 'High']))

"""## East"""

E_df = region_dfs['East'].groupby(
    ['Category', 'Size', 'B2B','promotion-ids', 'Fulfilment', 'Sales Channel ', 'fulfilled-by'],
    as_index=False
).agg({
    'Qty': 'sum',
    'Amount': 'sum'
})

E_df['Volume_Class'] = pd.qcut(
    E_df['Qty'],
    q=2,
    labels=[0, 1],
    duplicates='drop')

sns.countplot(x='Volume_Class', data=E_df, order=[0, 1], palette='viridis')
plt.show()

E_df[cat_cols] = E_df[cat_cols].astype('category')

#Create Independent and Dependent Variables
X4 = E_df.drop(['Qty', 'Amount', 'Volume_Class'], axis = 1)
y4 = E_df['Volume_Class']

X4 = pd.get_dummies(X4)

# Split the data into training and testing set
X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.2, random_state=428)

print(X4_train.shape)
print(X4_test.shape)
print(y4_train.shape)
print(y4_test.shape)

# Fit logistic regression
lr_model4 = LogisticRegression()
lr_model4.fit(X4_train,y4_train)

prediction_probE = lr_model4.predict_proba(X4_test)[:,1]
type(prediction_probE)
#predictions_threshold =
prediction_probE[prediction_probE > 0.4] = 1
prediction_probE[prediction_probE <= 0.4] = 0

print("\n Logistic Regression 0.4 threshold Report:\n", classification_report(y4_test, prediction_probE, target_names=['Low', 'High']))

# Amazon Sales SKU Classification Streamlit App
import streamlit as st
from sklearn.preprocessing import LabelEncoder
import plotly.express as px
import plotly.graph_objects as go

# Page configuration
st.set_page_config(page_title="Amazon SKU Classifier", page_icon="üì¶", layout="wide")

all_regional_data = pd.concat([
    N_df.assign(Region='North'),
    S_df.assign(Region='South'),
    E_df.assign(Region='East'),
    W_df.assign(Region='West')
], ignore_index=True)


# Title and description
st.title("üì¶ Amazon Sales SKU Classifier")
st.subheader("Predicting SKU Performance in Indian Regions")

# Add description
st.markdown("""
This application classifies SKUs based on whether they will sell more than 2 quantities in a specific region.
- **Class 0**: SKU will sell 2 or fewer quantities
- **Class 1**: SKU will sell more than 2 quantities
""")

# Sidebar for navigation
st.sidebar.title("Navigation")
nav = st.sidebar.radio("Choose Section", ["Home", "SKU Classification", "Data Analysis"])

# Home Section
if nav == 'Home':
    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("""
        ## About This Application

        This application helps predict SKU performance in different regions of India based on various product characteristics.

        **Features:**
        - Region-specific predictions for North, South, East, and West India
        - Classification based on multiple product attributes
        - Interactive prediction interface
        - Data visualization capabilities

        **How to Use:**
        1. Navigate to the "SKU Classification" section
        2. Select your target region
        3. Input product characteristics
        4. Get prediction results instantly
        """)

    with col2:
        # Display some statistics
        st.markdown("### Quick Stats")
        st.metric("Total Regions", "4")
        st.metric("Product Categories", "9")
        st.metric("Classification Classes", "2")

        # Calculate percentages by region
        region_stats = all_regional_data.groupby(['Region', 'Volume_Class']).size().unstack(fill_value=0)
        region_percentages = region_stats.div(region_stats.sum(axis=1), axis=0) * 100

        fig = go.Figure(data=[
            go.Bar(name='Class 0 (‚â§2 quantities)',
                  x=region_percentages.index,
                  y=region_percentages[0] if 0 in region_percentages.columns else [0]*len(region_percentages)),
            go.Bar(name='Class 1 (>2 quantities)',
                  x=region_percentages.index,
                  y=region_percentages[1] if 1 in region_percentages.columns else [0]*len(region_percentages))
        ])
        fig.update_layout(
            title="Actual Volume Class Distribution by Region (%)",
            barmode='stack',
            height=400,
            yaxis_title="Percentage (%)"
        )
        st.plotly_chart(fig, use_container_width=True)

# SKU Classification Section
elif nav == 'SKU Classification':
    st.header("üéØ SKU Performance Prediction")

    # Region selection
    st.markdown("### Step 1: Select Target Region")
    selected_region = st.selectbox("Choose the region for prediction:", REGIONS, index=0)

    st.markdown(f"**Selected Region:** {selected_region}")
    st.divider()
    if selected_region == 'North':
        model = lr_model
    elif selected_region == 'South':
        model = lr_model2
    elif selected_region == 'West':
        model = lr_model3
    elif selected_region == 'East':
        model = lr_model4

    # Input form
    st.markdown("### Step 2: Enter Product Details")

    col1, col2 = st.columns(2)

    with col1:
        category = st.selectbox("Product Category:", CATEGORIES, index=0)
        size = st.selectbox("Size:", SIZES, index=6)  # Default to 'L'
        b2b = st.selectbox("B2B:", B2B_OPTIONS, index=1)  # Default to 'FALSE'

    with col2:
        promotion_ids = st.selectbox("Promotion IDs:", PROMOTION_IDS, index=0)
        fulfillment = st.selectbox("Fulfillment:", FULFILLMENT, index=0)  # Default to 'Amazon'
        sales_channel = st.selectbox("Sales Channel:", SALES_CHANNEL, index=0)  # Default to 'Amazon.in'

    st.divider()

    # Prediction section
    st.markdown("### Step 3: Get Prediction")

    col1, col2, col3 = st.columns([1, 2, 1])

    with col2:
        if st.button("üöÄ Predict SKU Performance", type="primary", use_container_width=True):
            # Encode features
            encoded_features = encode_features(category, size, b2b, promotion_ids, fulfillment, sales_channel)

            # Make prediction (replace with your actual prediction logic)
            prediction = model.predict([encoded_features])[0]
            prediction_proba = model.predict_proba([encoded_features])[0]

            st.success("Prediction Complete!")

            # Display results
            col_result1, col_result2 = st.columns(2)

            with col_result1:
                if prediction == 1:
                    st.success(f"**Prediction: Class {prediction}**")
                    st.write("‚úÖ This SKU is predicted to sell **MORE than 2 quantities** in the selected region.")
                else:
                    st.warning(f"**Prediction: Class {prediction}**")
                    st.write("‚ö†Ô∏è This SKU is predicted to sell **2 or FEWER quantities** in the selected region.")

            with col_result2:
                st.markdown("**Prediction Confidence:**")
                st.write(f"Class 0 probability: {prediction_proba[0]:.2%}")
                st.write(f"Class 1 probability: {prediction_proba[1]:.2%}")

                # Confidence bar
                confidence = max(prediction_proba)
                st.progress(confidence)
                st.write(f"Confidence Level: {confidence:.2%}")

    # Display input summary
    with st.expander("üìã Input Summary"):
        input_data = {
            "Parameter": ["Region", "Category", "Size", "B2B", "Promotion IDs", "Fulfillment", "Sales Channel"],
            "Value": [selected_region, category, size, b2b, promotion_ids, fulfillment, sales_channel]
        }
        input_df = pd.DataFrame(input_data)
        st.table(input_df)

# Data Analysis Section
elif nav == 'Data Analysis':
    st.header("üìä Data Analysis & Insights")

    # Sample visualizations (replace with actual data analysis)
    col1, col2 = st.columns(2)

    with col1:
        # Category distribution
        category_counts = pd.DataFrame({
            'Category': df['Category'],
            'Count': df['Category'].value_counts()
        })

        fig1 = px.bar(category_counts, x='Category', y='Count',
                     title='SKU Distribution by Category',
                     color='Count', color_continuous_scale='viridis')
        fig1.update_xaxis(tickangle=45)
        st.plotly_chart(fig1, use_container_width=True)

    with col2:
        # Regional performance
        # Count Volume class = 1 from each regional dataframe
        regional_performance = pd.DataFrame({
            'Region': ['North', 'South', 'East', 'West'],
            'High_Performance_SKUs': [
                (N_df['Volume_Class'] == 1).sum(),
                (S_df['Volume_Class'] == 1).sum(),  # Note: S_df not S-df
                (E_df['Volume_Class'] == 1).sum(),
                (W_df['Volume_Class'] == 1).sum()
            ]
        })

        fig2 = px.pie(regional_performance, values='High_Performance_SKUs', names='Region',
                     title='High Performance SKUs by Region (Volume Class = 1)')
        st.plotly_chart(fig2, use_container_width=True)

    # Size distribution
    size_performance = all_regional_data[all_regional_data['Volume_Class'] == 1]['Size'].value_counts().reset_index()
    size_performance.columns = ['Size', 'Class_1_Count']

    fig3 = px.bar(size_performance, x='Size', y='Class_1_Count',
                 title='Class 1 Count by Size',
                 labels={'Class_1_Count': 'Number of Class 1 SKUs'})
    st.plotly_chart(fig3, use_container_width=True)

    # Feature importance
    st.markdown("### Feature Importance")
    def get_feature_importance_from_models(models, feature_names):
        """Extract feature importance from logistic regression models"""

        # Combine coefficients from all regional models
        all_coefficients = []

        for region, model in models.items():
            # Get absolute values of coefficients
            coeffs = np.abs(model.coef_[0])  # model.coef_[0] for binary classification
            all_coefficients.append(coeffs)

        # Average coefficients across all regions
        avg_coefficients = np.mean(all_coefficients, axis=0)

        # Normalize to get relative importance (optional)
        normalized_importance = avg_coefficients / np.sum(avg_coefficients)

        return normalized_importance

    # Use it in your code
    feature_names = ['Category', 'Size', 'B2B', 'Promotion IDs', 'Fulfillment', 'Sales Channel']

    actual_models = {
        'North': lr_model,     # Your North region model
        'South': lr_model2,    # Your South region model
        'East': lr_model4,     # Your East region model
        'West': lr_model3      # Your West region model
    }
    # Get actual importance from your models
    importance_scores = get_feature_importance_from_models(actual_models, feature_names)

    feature_importance = pd.DataFrame({
        'Feature': feature_names,
        'Importance': importance_scores
    })

    fig4 = px.bar(feature_importance, x='Importance', y='Feature', orientation='h',
                 title='Feature Importance for SKU Classification (Based on Coefficient Magnitudes)')
    st.plotly_chart(fig4, use_container_width=True)


# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>Amazon Sales SKU Classifier | Built with Streamlit</p>
    <p>For questions or support, contact your data science team</p>
</div>
""", unsafe_allow_html=True)

